{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply an image-based profiling pipeline using pycytominer\n",
    "\n",
    "As described fully in [Caicedo et al. 2017](https://doi.org/10.1038/nmeth.4397), an image-based profiling pipeline consists of three core steps:\n",
    "\n",
    "1. Aggregation\n",
    "2. Normalization\n",
    "3. Feature selection\n",
    "\n",
    "[Pycytominer](https://github.com/cytomining/pycytominer) is a python package, built on top of pandas, that facilitates all of these steps and more.\n",
    "\n",
    "### Data levels\n",
    "\n",
    "The concept of \"data levels\" is important to understand when implementing an image-based profiling pipeline.\n",
    "\n",
    "| Data | Level |\n",
    "| :---- | :---- |\n",
    "| Images | Level 1 |\n",
    "| Single cell profiles (SQLite) | Level 2 |\n",
    "| Aggregated profiles with metadata information | Level 3 |\n",
    "| Normalized aggregated profiles | Level 4a |\n",
    "| Normalized and feature selected profiles | Level 4b |\n",
    "| Consensus profiles | Level 5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "from pycytominer.aggregate import AggregateProfiles\n",
    "from pycytominer import annotate, normalize, feature_select, consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "plate_id = \"218360\"\n",
    "platemap = \"218360.txt\"\n",
    "\n",
    "sqlite_file = f\"sqlite:///{data_dir}/{plate_id}.sqlite\"\n",
    "sqlite_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = pathlib.Path(\"profiles\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load platemap file\n",
    "platemap_file = pathlib.Path(f\"{data_dir}/{platemap}\")\n",
    "platemap_df = pd.read_csv(platemap_file, sep=\"\\t\")\n",
    "\n",
    "print(platemap_df.shape)\n",
    "platemap_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Single cell aggregation\n",
    "\n",
    "In this step, **level 2 profiles** (single cells) are processed to **level 3 profiles** (well-level profiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the aggregation step\n",
    "ap = AggregateProfiles(\n",
    "    sqlite_file,\n",
    "    strata=[\"Metadata_Plate\", \"Metadata_Well\"],\n",
    "    features=\"infer\",\n",
    "    operation=\"median\",\n",
    "    output_file=\"none\",\n",
    "    compartments=[\"cells\", \"cytoplasm\", \"nuclei\"],\n",
    "    merge_cols=[\"TableNumber\", \"ImageNumber\"],\n",
    "    load_image_data=True,\n",
    "    subsample_frac=1,\n",
    "    subsample_n=\"all\",\n",
    "    subsampling_random_state=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count cells\n",
    "cell_count_df = ap.count_cells()\n",
    "\n",
    "cell_count_df = (\n",
    "    cell_count_df.merge(\n",
    "        platemap_df,\n",
    "        left_on=\"Metadata_Well\",\n",
    "        right_on=\"well_position\"\n",
    "    )\n",
    ")\n",
    "\n",
    "cell_count_file = pathlib.Path(f\"{output_dir}/cell_counts.tsv\")\n",
    "cell_count_df.to_csv(cell_count_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(cell_count_df.shape)\n",
    "cell_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the aggregation - output well level profiles\n",
    "output_file = pathlib.Path(f\"{output_dir}/{plate_id}.csv.gz\")\n",
    "\n",
    "# Aggregate profiles can output a file, or save the result to a variable\n",
    "# Here, we output the intermediate result to a file\n",
    "ap.aggregate_profiles(\n",
    "    output_file=output_file,\n",
    "    compute_subsample=True,\n",
    "    compression=\"gzip\",\n",
    "    float_format=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and preview what was output in the previous step \n",
    "aggregated_df = pd.read_csv(output_file)\n",
    "\n",
    "print(aggregated_df.shape)\n",
    "aggregated_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Annotate wells using the platemap file\n",
    "\n",
    "In this step, **level 3 profiles** (well-level profiles) are annotated with platemap metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate profiles\n",
    "annotate_file = pathlib.Path(f\"{output_dir}/{plate_id}_augmented.csv.gz\")\n",
    "\n",
    "annotate(\n",
    "    profiles=output_file,\n",
    "    platemap=platemap_df,\n",
    "    join_on=[\"Metadata_well_position\", \"Metadata_Well\"],\n",
    "    output_file=annotate_file,\n",
    "    compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and preview what was output in the previous step \n",
    "annotated_df = pd.read_csv(annotate_file)\n",
    "\n",
    "print(annotated_df.shape)\n",
    "annotated_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Normalize well-level profiles\n",
    "\n",
    "In this step, **level 3 profiles** (well-level profiles) are normalized to form **level 4a profiles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize profiles\n",
    "normalize_file = pathlib.Path(f\"{output_dir}/{plate_id}_normalized.csv.gz\")\n",
    "\n",
    "normalize(\n",
    "    profiles=annotate_file,\n",
    "    features=\"infer\",\n",
    "    meta_features=\"infer\",\n",
    "    samples=\"Metadata_treatment == '0.1% DMSO'\",\n",
    "    method=\"standardize\",\n",
    "    output_file=normalize_file,\n",
    "    compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and preview what was output in the previous step \n",
    "normalized_df = pd.read_csv(normalize_file)\n",
    "\n",
    "print(normalized_df.shape)\n",
    "normalized_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Apply feature selection\n",
    "\n",
    "In this step, we apply a series of feature selection steps to **level 4a profiles** (normalized well-level profiles) to form **level 4b profiles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature selection\n",
    "feature_select_file = pathlib.Path(f\"{output_dir}/{plate_id}_normalized_feature_select.csv.gz\")\n",
    "\n",
    "feature_select_opts = [\n",
    "    \"variance_threshold\",\n",
    "    \"drop_na_columns\",\n",
    "    \"correlation_threshold\",\n",
    "    \"blocklist\",\n",
    "    \"drop_outliers\"\n",
    "]\n",
    "\n",
    "feature_select(\n",
    "    profiles=normalize_file,\n",
    "    features=\"infer\",\n",
    "    samples=\"all\",\n",
    "    operation=feature_select_opts,\n",
    "    output_file=feature_select_file,\n",
    "    compression=\"gzip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and preview what was output in the previous step \n",
    "feature_select_df = pd.read_csv(feature_select_file)\n",
    "\n",
    "print(feature_select_df.shape)\n",
    "feature_select_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Form consensus signatures\n",
    "\n",
    "In this step, we collapse replicates (**level 4 profiles**) into a single profile.\n",
    "This forms **level 5 profiles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate consensus profiles\n",
    "consensus_file = pathlib.Path(f\"{output_dir}/{plate_id}_consensus.csv.gz\")\n",
    "\n",
    "consensus(\n",
    "    profiles=feature_select_df,\n",
    "    replicate_columns=[\"Metadata_clone_number\", \"Metadata_treatment\"],\n",
    "    operation=\"modz\",\n",
    "    features=\"infer\",\n",
    "    output_file=consensus_file,\n",
    "    modz_method=\"spearman\",\n",
    "    modz_min_weight=0.01,\n",
    "    modz_precision=4,\n",
    "    compression=\"gzip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and preview what was output in the previous step \n",
    "consensus_df = pd.read_csv(consensus_file)\n",
    "\n",
    "print(consensus_df.shape)\n",
    "consensus_df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
